# üìã PLANO DE SINCRONIZA√á√ÉO SUPABASE HITSS

**Data:** 15 de Janeiro de 2025  
**Projeto:** Sincroniza√ß√£o entre MCP-Supabase-Fabricio e MCP-Supabase-HITSS  
**Objetivo:** Replicar processo de automa√ß√£o HITSS entre projetos Supabase

---

## 1. AN√ÅLISE DA ESTRUTURA ATUAL

### 1.1 Projeto Origem (MCP-Supabase-Fabricio)
- **URL:** `https://supabase.com/dashboard/project/pwksgdjjkryqryqrvyja`
- **Tabela Principal:** `dre_hitss`
- **Status:** Estrutura definida, Edge Functions implementadas

### 1.2 Projeto Destino (MCP-Supabase-HITSS)
- **Projeto:** `app-financeiro`
- **Status:** Necessita replica√ß√£o da estrutura e automa√ß√£o

### 1.3 Estrutura da Tabela `dre_hitss`

```sql
CREATE TABLE IF NOT EXISTS public.dre_hitss (
    id BIGSERIAL PRIMARY KEY,
    execution_id TEXT NOT NULL,
    conta TEXT,
    descricao TEXT,
    valor DECIMAL(15,2),
    tipo TEXT,
    periodo TEXT,
    empresa TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

**Campos Identificados:**
- `id`: Chave prim√°ria auto-incremento
- `execution_id`: ID √∫nico da execu√ß√£o
- `conta`: C√≥digo da conta cont√°bil
- `descricao`: Descri√ß√£o da conta
- `valor`: Valor monet√°rio
- `tipo`: Tipo da conta (RECEITA/DESPESA)
- `periodo`: Per√≠odo de refer√™ncia
- `empresa`: Nome da empresa
- `created_at`: Timestamp de cria√ß√£o

---

## 2. MAPEAMENTO DAS EDGE FUNCTIONS

### 2.1 Edge Functions Existentes

#### `hitss-automation`
- **Fun√ß√£o:** Automa√ß√£o principal do processo HITSS
- **Responsabilidades:**
  - Obten√ß√£o de credenciais do Vault
  - Download de arquivo Excel do sistema HITSS
  - Registro de execu√ß√µes
  - Tratamento de erros

#### `hitss-data-processor`
- **Fun√ß√£o:** Processamento de dados XLSX
- **Responsabilidades:**
  - Parsing de arquivos Excel
  - Valida√ß√£o de dados
  - Transforma√ß√£o de estruturas
  - Gera√ß√£o de relat√≥rios de erro

#### `execute-dre-automation`
- **Fun√ß√£o:** Orquestra√ß√£o do processo DRE
- **Responsabilidades:**
  - Coordena√ß√£o entre servi√ßos
  - Inser√ß√£o de dados na tabela
  - Limpeza de dados antigos

### 2.2 Servi√ßos Compartilhados
- `_shared/auth.ts`: Autentica√ß√£o
- `_shared/cors.ts`: Configura√ß√£o CORS
- `_shared/database.ts`: Conex√£o com banco
- `_shared/logger.ts`: Sistema de logs
- `_shared/types.ts`: Defini√ß√µes de tipos

---

## 3. PLANO DE REPLICA√á√ÉO

### 3.1 Fase 1: Prepara√ß√£o da Infraestrutura

#### 3.1.1 Cria√ß√£o da Tabela no Projeto Destino

```sql
-- Script para MCP-Supabase-HITSS
CREATE TABLE IF NOT EXISTS public.dre_hitss (
    id BIGSERIAL PRIMARY KEY,
    execution_id TEXT NOT NULL,
    conta TEXT,
    descricao TEXT,
    valor DECIMAL(15,2),
    tipo TEXT,
    periodo TEXT,
    empresa TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- √çndices para performance
CREATE INDEX IF NOT EXISTS idx_dre_hitss_execution_id ON dre_hitss(execution_id);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_empresa ON dre_hitss(empresa);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_periodo ON dre_hitss(periodo);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_created_at ON dre_hitss(created_at);

-- Permiss√µes
GRANT SELECT, INSERT, UPDATE, DELETE ON dre_hitss TO authenticated;
GRANT SELECT, INSERT, UPDATE, DELETE ON dre_hitss TO service_role;
```

#### 3.1.2 Tabela de Controle de Execu√ß√µes

```sql
CREATE TABLE IF NOT EXISTS public.automation_executions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    status VARCHAR(20) NOT NULL CHECK (status IN ('running', 'completed', 'failed')),
    started_at TIMESTAMPTZ NOT NULL,
    completed_at TIMESTAMPTZ,
    records_processed INTEGER DEFAULT 0,
    records_failed INTEGER DEFAULT 0,
    error_message TEXT,
    execution_details JSONB
);

-- √çndices
CREATE INDEX IF NOT EXISTS idx_automation_executions_status ON automation_executions(status);
CREATE INDEX IF NOT EXISTS idx_automation_executions_started_at ON automation_executions(started_at DESC);
```

#### 3.1.3 Configura√ß√£o do Vault

```sql
-- Configurar credenciais no Vault
INSERT INTO vault.secrets (name, secret) VALUES 
('HITSS_USERNAME', 'seu_usuario_hitss'),
('HITSS_PASSWORD', 'sua_senha_hitss'),
('HITSS_BASE_URL', 'https://hitsscontrol.globalhitss.com.br'),
('HITSS_LINK_DOWNLOAD', 'https://hitsscontrol.globalhitss.com.br/api/api/export/xls?...');
```

### 3.2 Fase 2: Replica√ß√£o das Edge Functions

#### 3.2.1 Estrutura de Diret√≥rios

```
supabase/functions/
‚îú‚îÄ‚îÄ _shared/
‚îÇ   ‚îú‚îÄ‚îÄ auth.ts
‚îÇ   ‚îú‚îÄ‚îÄ cors.ts
‚îÇ   ‚îú‚îÄ‚îÄ database.ts
‚îÇ   ‚îú‚îÄ‚îÄ logger.ts
‚îÇ   ‚îî‚îÄ‚îÄ types.ts
‚îú‚îÄ‚îÄ hitss-automation/
‚îÇ   ‚îú‚îÄ‚îÄ index.ts
‚îÇ   ‚îú‚îÄ‚îÄ hitss-automation-service.ts
‚îÇ   ‚îú‚îÄ‚îÄ hitss-data-processor.ts
‚îÇ   ‚îî‚îÄ‚îÄ types.ts
‚îú‚îÄ‚îÄ execute-dre-automation/
‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îî‚îÄ‚îÄ deno.json
```

#### 3.2.2 Configura√ß√£o do deno.json

```json
{
  "tasks": {
    "start": "deno run --allow-all --watch=static/,routes/ dev.ts"
  },
  "imports": {
    "@supabase/supabase-js": "https://esm.sh/@supabase/supabase-js@2",
    "cors": "https://deno.land/x/cors@v1.2.2/mod.ts"
  },
  "compilerOptions": {
    "allowJs": true,
    "lib": ["deno.window"],
    "strict": true
  }
}
```

#### 3.2.3 Edge Function Principal

```typescript
// supabase/functions/hitss-automation/index.ts
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { corsHeaders } from '../_shared/cors.ts'
import { logger } from '../_shared/logger.ts'

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    logger.info('üöÄ Iniciando automa√ß√£o HITSS...')

    const supabaseUrl = Deno.env.get('SUPABASE_URL')!
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    const supabase = createClient(supabaseUrl, supabaseKey)

    // 1. Registrar execu√ß√£o
    const execution = await registerExecution(supabase)
    
    // 2. Obter credenciais do Vault
    const credentials = await getCredentialsFromVault(supabase)
    
    // 3. Processar dados HITSS
    const result = await processHITSS(credentials, supabase, execution.id)
    
    // 4. Atualizar execu√ß√£o
    await updateExecution(supabase, execution.id, {
      status: 'completed',
      completed_at: new Date().toISOString(),
      records_processed: result.recordsProcessed
    })

    return new Response(JSON.stringify({
      success: true,
      executionId: execution.id,
      recordsProcessed: result.recordsProcessed
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    })

  } catch (error) {
    logger.error('‚ùå Erro na automa√ß√£o HITSS:', error)
    
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    })
  }
})
```

---

## 4. ESTRAT√âGIA DE SINCRONIZA√á√ÉO

### 4.1 Sincroniza√ß√£o Unidirecional

**Origem:** MCP-Supabase-Fabricio ‚Üí **Destino:** MCP-Supabase-HITSS

#### 4.1.1 Edge Function de Sincroniza√ß√£o

```typescript
// supabase/functions/sync-dre-data/index.ts
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const ORIGEM_URL = 'https://pwksgdjjkryqryqrvyja.supabase.co'
const ORIGEM_KEY = 'sua_service_role_key_origem'

serve(async (req) => {
  try {
    // Cliente origem
    const origemClient = createClient(ORIGEM_URL, ORIGEM_KEY)
    
    // Cliente destino (atual)
    const destinoClient = createClient(
      Deno.env.get('SUPABASE_URL')!,
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    )

    // Buscar dados da origem
    const { data: dadosOrigem, error: erroOrigem } = await origemClient
      .from('dre_hitss')
      .select('*')
      .gte('created_at', new Date(Date.now() - 24*60*60*1000).toISOString())

    if (erroOrigem) throw erroOrigem

    // Inserir no destino
    const { data: dadosInseridos, error: erroInsercao } = await destinoClient
      .from('dre_hitss')
      .upsert(dadosOrigem, { onConflict: 'execution_id,conta' })

    if (erroInsercao) throw erroInsercao

    return new Response(JSON.stringify({
      success: true,
      recordsSynced: dadosOrigem?.length || 0
    }))

  } catch (error) {
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), { status: 500 })
  }
})
```

### 4.2 Sincroniza√ß√£o Bidirecional (Opcional)

#### 4.2.1 Controle de Conflitos

```sql
-- Adicionar campos de controle
ALTER TABLE dre_hitss ADD COLUMN IF NOT EXISTS sync_source VARCHAR(50) DEFAULT 'local';
ALTER TABLE dre_hitss ADD COLUMN IF NOT EXISTS last_sync_at TIMESTAMPTZ;
ALTER TABLE dre_hitss ADD COLUMN IF NOT EXISTS sync_hash VARCHAR(64);
```

---

## 5. CONFIGURA√á√ÉO DE CRON JOBS

### 5.1 Automa√ß√£o Di√°ria

```sql
-- Habilitar extens√£o pg_cron
CREATE EXTENSION IF NOT EXISTS pg_cron;

-- Fun√ß√£o para chamar automa√ß√£o
CREATE OR REPLACE FUNCTION call_hitss_automation()
RETURNS TEXT AS $$
DECLARE
    response TEXT;
    project_url TEXT := current_setting('app.settings.supabase_url');
    service_key TEXT := current_setting('app.settings.service_role_key');
BEGIN
    SELECT content INTO response
    FROM http((
        'POST',
        project_url || '/functions/v1/hitss-automation',
        ARRAY[http_header('Authorization', 'Bearer ' || service_key)],
        'application/json',
        '{}'
    ));
    
    RETURN 'Automa√ß√£o executada: ' || COALESCE(response, 'sem resposta');
EXCEPTION
    WHEN OTHERS THEN
        RETURN 'Erro na automa√ß√£o: ' || SQLERRM;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Agendar execu√ß√£o di√°ria √†s 8h UTC (5h BRT)
SELECT cron.schedule(
    'hitss-automation-daily',
    '0 8 * * 1-5',  -- Segunda a sexta
    'SELECT call_hitss_automation();'
);
```

### 5.2 Sincroniza√ß√£o Hor√°ria

```sql
-- Fun√ß√£o para sincroniza√ß√£o
CREATE OR REPLACE FUNCTION call_sync_dre_data()
RETURNS TEXT AS $$
DECLARE
    response TEXT;
    project_url TEXT := current_setting('app.settings.supabase_url');
    service_key TEXT := current_setting('app.settings.service_role_key');
BEGIN
    SELECT content INTO response
    FROM http((
        'POST',
        project_url || '/functions/v1/sync-dre-data',
        ARRAY[http_header('Authorization', 'Bearer ' || service_key)],
        'application/json',
        '{}'
    ));
    
    RETURN 'Sincroniza√ß√£o executada: ' || COALESCE(response, 'sem resposta');
EXCEPTION
    WHEN OTHERS THEN
        RETURN 'Erro na sincroniza√ß√£o: ' || SQLERRM;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Agendar sincroniza√ß√£o a cada 2 horas
SELECT cron.schedule(
    'sync-dre-data-hourly',
    '0 */2 * * *',
    'SELECT call_sync_dre_data();'
);
```

---

## 6. SCRIPTS DE MIGRA√á√ÉO

### 6.1 Migra√ß√£o Inicial

```sql
-- migration_001_create_dre_structure.sql
-- Criar estrutura completa para DRE HITSS

BEGIN;

-- Tabela principal
CREATE TABLE IF NOT EXISTS public.dre_hitss (
    id BIGSERIAL PRIMARY KEY,
    execution_id TEXT NOT NULL,
    conta TEXT,
    descricao TEXT,
    valor DECIMAL(15,2),
    tipo TEXT,
    periodo TEXT,
    empresa TEXT,
    sync_source VARCHAR(50) DEFAULT 'local',
    last_sync_at TIMESTAMPTZ,
    sync_hash VARCHAR(64),
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Tabela de execu√ß√µes
CREATE TABLE IF NOT EXISTS public.automation_executions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    status VARCHAR(20) NOT NULL CHECK (status IN ('running', 'completed', 'failed')),
    started_at TIMESTAMPTZ NOT NULL,
    completed_at TIMESTAMPTZ,
    records_processed INTEGER DEFAULT 0,
    records_failed INTEGER DEFAULT 0,
    error_message TEXT,
    execution_details JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- √çndices
CREATE INDEX IF NOT EXISTS idx_dre_hitss_execution_id ON dre_hitss(execution_id);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_empresa ON dre_hitss(empresa);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_periodo ON dre_hitss(periodo);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_created_at ON dre_hitss(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_dre_hitss_sync_source ON dre_hitss(sync_source);

CREATE INDEX IF NOT EXISTS idx_automation_executions_status ON automation_executions(status);
CREATE INDEX IF NOT EXISTS idx_automation_executions_started_at ON automation_executions(started_at DESC);

-- Permiss√µes
GRANT SELECT, INSERT, UPDATE, DELETE ON dre_hitss TO authenticated;
GRANT SELECT, INSERT, UPDATE, DELETE ON dre_hitss TO service_role;
GRANT SELECT, INSERT, UPDATE, DELETE ON automation_executions TO authenticated;
GRANT SELECT, INSERT, UPDATE, DELETE ON automation_executions TO service_role;

-- Trigger para updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_dre_hitss_updated_at
    BEFORE UPDATE ON dre_hitss
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

COMMIT;
```

### 6.2 Script de Valida√ß√£o

```sql
-- validate_migration.sql
-- Validar estrutura ap√≥s migra√ß√£o

-- Verificar tabelas
SELECT 
    table_name,
    table_type
FROM information_schema.tables 
WHERE table_schema = 'public' 
AND table_name IN ('dre_hitss', 'automation_executions');

-- Verificar colunas da dre_hitss
SELECT 
    column_name,
    data_type,
    is_nullable,
    column_default
FROM information_schema.columns 
WHERE table_name = 'dre_hitss' 
AND table_schema = 'public'
ORDER BY ordinal_position;

-- Verificar √≠ndices
SELECT 
    indexname,
    indexdef
FROM pg_indexes 
WHERE tablename IN ('dre_hitss', 'automation_executions')
AND schemaname = 'public';

-- Verificar permiss√µes
SELECT 
    table_name,
    grantee,
    privilege_type
FROM information_schema.table_privileges 
WHERE table_name IN ('dre_hitss', 'automation_executions')
AND table_schema = 'public';
```

---

## 7. MONITORAMENTO E LOGS

### 7.1 Sistema de Logs

#### 7.1.1 Tabela de Logs

```sql
CREATE TABLE IF NOT EXISTS public.system_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    level VARCHAR(10) NOT NULL CHECK (level IN ('DEBUG', 'INFO', 'WARN', 'ERROR')),
    message TEXT NOT NULL,
    context JSONB,
    source VARCHAR(100),
    execution_id TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_system_logs_level ON system_logs(level);
CREATE INDEX IF NOT EXISTS idx_system_logs_created_at ON system_logs(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_system_logs_execution_id ON system_logs(execution_id);
```

#### 7.1.2 Fun√ß√£o de Log

```typescript
// _shared/logger.ts
export class Logger {
  private supabase: any
  private executionId?: string

  constructor(supabase: any, executionId?: string) {
    this.supabase = supabase
    this.executionId = executionId
  }

  async log(level: 'DEBUG' | 'INFO' | 'WARN' | 'ERROR', message: string, context?: any) {
    try {
      await this.supabase
        .from('system_logs')
        .insert({
          level,
          message,
          context,
          source: 'hitss-automation',
          execution_id: this.executionId,
          created_at: new Date().toISOString()
        })
    } catch (error) {
      console.error('Erro ao salvar log:', error)
    }
    
    // Log tamb√©m no console
    console.log(`[${level}] ${message}`, context || '')
  }

  async info(message: string, context?: any) {
    await this.log('INFO', message, context)
  }

  async error(message: string, context?: any) {
    await this.log('ERROR', message, context)
  }

  async warn(message: string, context?: any) {
    await this.log('WARN', message, context)
  }

  async debug(message: string, context?: any) {
    await this.log('DEBUG', message, context)
  }
}
```

### 7.2 Dashboard de Monitoramento

#### 7.2.1 Queries de Monitoramento

```sql
-- Status das execu√ß√µes (√∫ltimas 24h)
SELECT 
    status,
    COUNT(*) as total,
    AVG(records_processed) as avg_records,
    MAX(completed_at - started_at) as max_duration
FROM automation_executions 
WHERE started_at >= NOW() - INTERVAL '24 hours'
GROUP BY status;

-- Logs de erro (√∫ltimas 24h)
SELECT 
    message,
    context,
    execution_id,
    created_at
FROM system_logs 
WHERE level = 'ERROR' 
AND created_at >= NOW() - INTERVAL '24 hours'
ORDER BY created_at DESC;

-- Performance por hora
SELECT 
    DATE_TRUNC('hour', started_at) as hora,
    COUNT(*) as execucoes,
    AVG(records_processed) as media_registros,
    AVG(EXTRACT(EPOCH FROM (completed_at - started_at))) as duracao_media_segundos
FROM automation_executions 
WHERE started_at >= NOW() - INTERVAL '7 days'
AND status = 'completed'
GROUP BY DATE_TRUNC('hour', started_at)
ORDER BY hora DESC;
```

### 7.3 Alertas

#### 7.3.1 Edge Function de Alertas

```typescript
// supabase/functions/check-system-health/index.ts
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

serve(async (req) => {
  try {
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL')!,
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    )

    // Verificar execu√ß√µes falhadas nas √∫ltimas 2 horas
    const { data: failedExecutions } = await supabase
      .from('automation_executions')
      .select('*')
      .eq('status', 'failed')
      .gte('started_at', new Date(Date.now() - 2*60*60*1000).toISOString())

    // Verificar execu√ß√µes em andamento h√° mais de 1 hora
    const { data: stuckExecutions } = await supabase
      .from('automation_executions')
      .select('*')
      .eq('status', 'running')
      .lte('started_at', new Date(Date.now() - 60*60*1000).toISOString())

    const alerts = []

    if (failedExecutions && failedExecutions.length > 0) {
      alerts.push({
        type: 'FAILED_EXECUTIONS',
        count: failedExecutions.length,
        message: `${failedExecutions.length} execu√ß√µes falharam nas √∫ltimas 2 horas`
      })
    }

    if (stuckExecutions && stuckExecutions.length > 0) {
      alerts.push({
        type: 'STUCK_EXECUTIONS',
        count: stuckExecutions.length,
        message: `${stuckExecutions.length} execu√ß√µes travadas h√° mais de 1 hora`
      })
    }

    // Enviar alertas se necess√°rio
    if (alerts.length > 0) {
      await sendAlerts(alerts)
    }

    return new Response(JSON.stringify({
      success: true,
      alerts: alerts.length,
      details: alerts
    }))

  } catch (error) {
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), { status: 500 })
  }
})

async function sendAlerts(alerts: any[]) {
  // Implementar envio de alertas (email, Slack, etc.)
  console.log('üö® Alertas detectados:', alerts)
}
```

---

## 8. TRATAMENTO DE ERROS E ROLLBACK

### 8.1 Estrat√©gias de Retry

```typescript
// _shared/retry.ts
export class RetryManager {
  static async withRetry<T>(
    operation: () => Promise<T>,
    maxRetries: number = 3,
    delayMs: number = 1000
  ): Promise<T> {
    let lastError: Error

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await operation()
      } catch (error) {
        lastError = error
        
        if (attempt === maxRetries) {
          throw error
        }

        // Delay exponencial
        const delay = delayMs * Math.pow(2, attempt - 1)
        await new Promise(resolve => setTimeout(resolve, delay))
      }
    }

    throw lastError!
  }
}
```

### 8.2 Sistema de Rollback

```typescript
// _shared/transaction.ts
export class TransactionManager {
  private supabase: any
  private operations: Array<() => Promise<void>> = []

  constructor(supabase: any) {
    this.supabase = supabase
  }

  addRollbackOperation(operation: () => Promise<void>) {
    this.operations.push(operation)
  }

  async rollback() {
    for (const operation of this.operations.reverse()) {
      try {
        await operation()
      } catch (error) {
        console.error('Erro no rollback:', error)
      }
    }
  }

  async executeWithRollback<T>(operation: () => Promise<T>): Promise<T> {
    try {
      return await operation()
    } catch (error) {
      await this.rollback()
      throw error
    }
  }
}
```

### 8.3 Backup Autom√°tico

```sql
-- Fun√ß√£o de backup
CREATE OR REPLACE FUNCTION backup_dre_data()
RETURNS TEXT AS $$
DECLARE
    backup_table TEXT;
    record_count INTEGER;
BEGIN
    -- Nome da tabela de backup
    backup_table := 'dre_hitss_backup_' || TO_CHAR(NOW(), 'YYYYMMDD_HH24MI');
    
    -- Criar backup
    EXECUTE format('CREATE TABLE %I AS SELECT * FROM dre_hitss', backup_table);
    
    -- Contar registros
    EXECUTE format('SELECT COUNT(*) FROM %I', backup_table) INTO record_count;
    
    RETURN format('Backup criado: %s com %s registros', backup_table, record_count);
EXCEPTION
    WHEN OTHERS THEN
        RETURN 'Erro no backup: ' || SQLERRM;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Agendar backup di√°rio
SELECT cron.schedule(
    'backup-dre-daily',
    '0 2 * * *',  -- 2h da manh√£
    'SELECT backup_dre_data();'
);
```

---

## 9. CRONOGRAMA DE IMPLEMENTA√á√ÉO

### 9.1 Semana 1: Prepara√ß√£o
- **Dia 1-2:** An√°lise detalhada da estrutura atual
- **Dia 3-4:** Cria√ß√£o das tabelas no projeto destino
- **Dia 5:** Configura√ß√£o do Vault e credenciais

### 9.2 Semana 2: Desenvolvimento
- **Dia 1-2:** Implementa√ß√£o das Edge Functions b√°sicas
- **Dia 3-4:** Desenvolvimento do processador de dados
- **Dia 5:** Testes unit√°rios e integra√ß√£o

### 9.3 Semana 3: Automa√ß√£o
- **Dia 1-2:** Configura√ß√£o dos cron jobs
- **Dia 3-4:** Implementa√ß√£o do sistema de logs
- **Dia 5:** Sistema de monitoramento e alertas

### 9.4 Semana 4: Testes e Deploy
- **Dia 1-2:** Testes de carga e performance
- **Dia 3-4:** Testes de failover e rollback
- **Dia 5:** Deploy em produ√ß√£o

### 9.5 Semana 5: Monitoramento
- **Dia 1-5:** Monitoramento intensivo e ajustes

---

## 10. CHECKLIST DE IMPLEMENTA√á√ÉO

### 10.1 Infraestrutura
- [ ] Criar tabela `dre_hitss` no projeto destino
- [ ] Criar tabela `automation_executions`
- [ ] Criar tabela `system_logs`
- [ ] Configurar √≠ndices de performance
- [ ] Configurar permiss√µes RLS
- [ ] Configurar credenciais no Vault

### 10.2 Edge Functions
- [ ] Implementar `hitss-automation`
- [ ] Implementar `hitss-data-processor`
- [ ] Implementar `execute-dre-automation`
- [ ] Implementar `sync-dre-data`
- [ ] Implementar `check-system-health`
- [ ] Configurar servi√ßos compartilhados

### 10.3 Automa√ß√£o
- [ ] Configurar cron job di√°rio
- [ ] Configurar cron job de sincroniza√ß√£o
- [ ] Configurar cron job de backup
- [ ] Configurar cron job de health check
- [ ] Testar execu√ß√£o manual

### 10.4 Monitoramento
- [ ] Implementar sistema de logs
- [ ] Configurar alertas de falha
- [ ] Configurar dashboard de monitoramento
- [ ] Implementar m√©tricas de performance
- [ ] Configurar notifica√ß√µes

### 10.5 Testes
- [ ] Testes unit√°rios das Edge Functions
- [ ] Testes de integra√ß√£o
- [ ] Testes de carga
- [ ] Testes de failover
- [ ] Testes de rollback

---

## 11. CONSIDERA√á√ïES FINAIS

### 11.1 Seguran√ßa
- Todas as credenciais devem ser armazenadas no Vault
- Usar HTTPS para todas as comunica√ß√µes
- Implementar rate limiting nas Edge Functions
- Configurar Row Level Security (RLS)

### 11.2 Performance
- Implementar cache para consultas frequentes
- Usar √≠ndices apropriados
- Processar dados em lotes
- Monitorar uso de recursos

### 11.3 Manuten√ß√£o
- Backup autom√°tico di√°rio
- Limpeza de logs antigos
- Monitoramento de espa√ßo em disco
- Atualiza√ß√µes regulares das depend√™ncias

### 11.4 Documenta√ß√£o
- Manter documenta√ß√£o atualizada
- Documentar mudan√ßas na estrutura
- Criar runbooks para opera√ß√µes
- Treinar equipe de suporte

---

**Status:** üìã Plano Completo  
**Pr√≥ximo Passo:** Iniciar Fase 1 - Prepara√ß√£o da Infraestrutura  
**Respons√°vel:** Equipe de Desenvolvimento  
**Prazo Estimado:** 5 semanas